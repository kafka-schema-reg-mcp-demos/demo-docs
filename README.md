# ğŸ¤– AI-Powered Kafka Schema Management

**Transform how you manage Kafka schemas with natural language commands through any MCP-compatible AI client**

[![ğŸš€ Live Demo](https://img.shields.io/badge/ğŸš€-Live%20Demo-blue?style=for-the-badge)](https://github.com/kafka-schema-reg-mcp-demos/demo-deployment) [![ğŸ“š Documentation](https://img.shields.io/badge/ğŸ“š-Documentation-green?style=for-the-badge)](https://github.com/aywengo/kafka-schema-reg-mcp) [![ğŸ¨ Demo Schemas](https://img.shields.io/badge/ğŸ¨-Demo%20Schemas-orange?style=for-the-badge)](https://github.com/kafka-schema-reg-mcp-demos/demo-schemas)

---

## ğŸ¯ What if managing Kafka schemas was as simple as talking to any AI assistant?

Instead of wrestling with APIs, CLIs, and complex configurations, imagine:

```
You: "Register a new user profile schema for our e-commerce platform with id, name, email, and preferences"

AI Assistant: I'll create and register that schema for you in the development registry under the ecommerce context.

âœ… Schema registered successfully!
âœ… Compatibility verified with existing schemas
âœ… Available in development environment
```

**That's the power of the Kafka Schema Registry MCP Server** - bringing AI-driven schema management to any MCP-compatible IDE or AI assistant.

---

## ğŸ—ï¸ Architecture: Local vs Remote Setup

Our Kafka Schema Registry MCP implementation supports both **local development** and **remote enterprise** deployments:

### **ğŸ  Local Development Setup**
Perfect for development, testing, and learning:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claude App    â”‚    â”‚   VS Code       â”‚    â”‚   Cursor IDE    â”‚
â”‚   (Desktop)     â”‚    â”‚   + Copilot     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTP/SSE
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Local MCP Server      â”‚
                    â”‚    (docker-compose)       â”‚
                    â”‚      localhost:38000      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚                         â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
  â”‚    Dev    â”‚            â”‚  Staging  â”‚            â”‚   Prod    â”‚
  â”‚ Registry  â”‚            â”‚ Registry  â”‚            â”‚ Registry  â”‚
  â”‚   :8081   â”‚            â”‚   :8082   â”‚            â”‚   :8083   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **ğŸŒ Remote Enterprise Setup**
Production-ready deployment with centralized authentication:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claude App    â”‚    â”‚   VS Code       â”‚    â”‚  JetBrains IDE  â”‚
â”‚   (Desktop)     â”‚    â”‚   + Copilot     â”‚    â”‚    + AI         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTPS/SSE + GitHub OAuth
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Remote MCP Server      â”‚
                    â”‚   (Kubernetes/Cloud)      â”‚
                    â”‚   your-domain.com:443     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚                         â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
  â”‚Enterprise â”‚            â”‚Enterprise â”‚            â”‚Enterprise â”‚
  â”‚   Dev     â”‚            â”‚ Staging   â”‚            â”‚   Prod    â”‚
  â”‚ Registry  â”‚            â”‚ Registry  â”‚            â”‚ Registry  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ MCP Client Compatibility

The **Model Context Protocol (MCP)** is an open standard that enables AI models to interact with external tools and services through a unified interface. Our Kafka Schema Registry MCP Server works seamlessly with any MCP-compatible client:

### **ğŸ¨ Supported AI Clients & IDEs**

<table>
<tr>
<td width="25%" align="center">
<h4>ğŸ¤– <a href="#claude-desktop-setup">Claude Desktop</a></h4>
<p><strong>Status:</strong> âœ… Full Support</p>
<ul>
<li>Native MCP integration</li>
<li>Natural language commands</li>
<li>Multi-registry support</li>
<li>GitHub OAuth integration</li>
</ul>
</td>
<td width="25%" align="center">
<h4>ğŸ’» <a href="#vs-code-copilot-setup">VS Code + Copilot</a></h4>
<p><strong>Status:</strong> âœ… Agent Mode (Preview)</p>
<ul>
<li>GitHub Copilot agent mode</li>
<li>Workspace/user configuration</li>
<li>Tool integration in chat</li>
<li>Auto-discovery support</li>
</ul>
</td>
<td width="25%" align="center">
<h4>âš¡ <a href="#cursor-ide-setup">Cursor IDE</a></h4>
<p><strong>Status:</strong> âœ… Full Support</p>
<ul>
<li>One-click MCP installation</li>
<li>Project/global configuration</li>
<li>Agent & Composer modes</li>
<li>OAuth server support</li>
</ul>
</td>
<td width="25%" align="center">
<h4>ğŸ§  <a href="#jetbrains-setup">JetBrains IDEs</a></h4>
<p><strong>Status:</strong> âœ… Full Support (2025.1+)</p>
<ul>
<li>IntelliJ IDEA, PyCharm, WebStorm</li>
<li>AI Assistant integration</li>
<li>Codebase-mode support</li>
<li>MCP proxy support</li>
</ul>
</td>
</tr>
</table>

### **ğŸŒ Additional MCP Clients**

- **Microsoft Copilot Studio**: Enterprise-grade MCP integration
- **Eclipse IDE**: Copilot with MCP support  
- **Xcode**: GitHub Copilot agent mode
- **Emacs**: MCP client with gptel/llm integration
- **Warp Terminal**: AI-powered terminal with MCP
- **And many more**: [See full list â†’](https://modelcontextprotocol.io/clients)

---

## ğŸš€ Quick Setup Guide

Choose your deployment model:

### **ğŸ  Option 1: Local Development Setup**

#### Step 1: Start Local Infrastructure

```bash
# Clone the demo deployment
git clone https://github.com/kafka-schema-reg-mcp-demos/demo-deployment.git
cd demo-deployment

# Configure GitHub OAuth (optional for local dev)
cp .env.example .env
# Edit .env with your GitHub OAuth credentials

# Start the complete environment
docker-compose -f docker-compose.github-oauth.yml up -d

# Wait for services to be ready (1-2 minutes)
docker-compose ps

# Load demo data
./scripts/setup-demo-data.sh
```

This starts:
- **MCP Server**: `localhost:38000` (with GitHub OAuth)
- **Schema Registries**: Dev (8081), Staging (8082), Production (8083)
- **Demo UI**: `localhost:3000`
- **Monitoring**: Prometheus (9090), Grafana (3001)

#### Step 2: Configure Your IDE/AI Client

**ğŸ”‘ Authentication Options:**
- **With GitHub OAuth**: Use personal access token with org membership
- **Local Development**: Set `DEV_MODE=true` in .env (no auth required)

Now configure your client to connect to the **existing MCP server**:

### **ğŸŒ Option 2: Remote Enterprise Setup**

For production deployments, deploy the MCP server to your infrastructure (Kubernetes, Docker Swarm, etc.) and configure clients to connect to the remote endpoint.

---

## ğŸ› ï¸ Client Configuration Examples

> **Important**: Clients connect to existing MCP servers via HTTP/SSE, they do **not** create Docker containers

### Claude Desktop Setup

Connect to your local or remote MCP server:

```json
{
  "mcpServers": {
    "kafka-schema-registry": {
      "command": "mcp-client-http", 
      "args": [
        "--url", "http://localhost:38000",
        "--auth", "github-oauth",
        "--org", "kafka-schema-reg-mcp-demos"
      ],
      "env": {
        "GITHUB_TOKEN": "your_github_personal_access_token"
      }
    }
  }
}
```

For remote servers, change the URL:
```json
"--url", "https://your-mcp-server.company.com"
```

### VS Code + Copilot Setup

Create `.vscode/settings.json` in your workspace:

```json
{
  "mcp.servers": {
    "kafka-schema-registry": {
      "transport": "sse",
      "endpoint": "http://localhost:38000/mcp/sse", 
      "headers": {
        "Authorization": "Bearer your_github_personal_access_token",
        "X-GitHub-Org": "kafka-schema-reg-mcp-demos"
      }
    }
  }
}
```

### Cursor IDE Setup

Create `.cursor/settings.json` in your project:

```json
{
  "mcp.servers": {
    "kafka-schema-registry": {
      "transport": "sse",
      "endpoint": "http://localhost:38000/mcp/sse",
      "headers": {
        "Authorization": "Bearer your_github_personal_access_token",
        "X-GitHub-Org": "kafka-schema-reg-mcp-demos"
      }
    }
  }
}
```

### JetBrains IDEs Setup

In **Settings â†’ Tools â†’ AI Assistant â†’ Model Context Protocol (MCP)**:

```json
{
  "servers": {
    "kafka-schema-registry": {
      "transport": "sse",
      "endpoint": "http://localhost:38000/mcp/sse",
      "headers": {
        "Authorization": "Bearer your_github_personal_access_token",
        "X-GitHub-Org": "kafka-schema-reg-mcp-demos"
      }
    }
  }
}
```

---

## ğŸ” GitHub OAuth Authentication

### Setting Up GitHub Authentication

1. **Create GitHub OAuth App**:
   - Go to: https://github.com/settings/applications/new
   - Application name: "My Schema Registry MCP"
   - Homepage URL: `http://localhost:3000` (or your domain)
   - Authorization callback: `http://localhost:38000/auth/callback`

2. **Generate Personal Access Token**:
   - Go to: https://github.com/settings/tokens
   - Generate token with appropriate scopes:
     - `public_repo` - Read access to schemas
     - `repo` - Write access to schemas  
     - `admin:org` - Full admin access (if org member)

### Permission Levels

| GitHub Scope | MCP Access | Description |
|--------------|------------|-------------|
| `public_repo` | **Read** | View schemas, export documentation |
| `repo` | **Write** | Register schemas, update configs (+ read) |
| `admin:org` | **Admin** | Delete subjects, manage production (+ write + read) |

### Team-Based Access Control

Configure team-based permissions in your `.env`:

```bash
GITHUB_ORG=kafka-schema-reg-mcp-demos
GITHUB_TEAM_READ=community      # Read access
GITHUB_TEAM_WRITE=developers    # Write access  
GITHUB_TEAM_ADMIN=maintainers   # Admin access
```

---

## ğŸŒŸ Why This Changes Everything

### **Before**: Traditional Schema Management
```bash
# Complex CLI commands
confluent schema-registry subject list --config-file config.properties

# Manual JSON crafting  
curl -X POST -H "Content-Type: application/json" \
  --data '{"schema": "{\"type\":\"record\",...}"}' \
  http://localhost:8081/subjects/user-profile/versions

# Separate tools for different operations
# No AI assistance or natural language interface
# Context switching between documentation and CLI
```

### **After**: AI-Powered Schema Management
```
You: "Show me all schemas in the production environment"
You: "Check if this schema evolution is backward compatible"  
You: "Migrate user-events schema from staging to production"
You: "Export all e-commerce schemas for documentation"
```

**Any AI assistant handles all the complexity while you focus on the business logic.**

---

## ğŸ¬ Enterprise Use Cases

### **ğŸ¯ Multi-Environment Schema Promotion**

```
DevOps Engineer: "The order-events schema tested successfully in staging. 
                  Promote it to production."

AI Assistant: I'll migrate the order-events schema from staging to production.
              [Performs cross-registry migration]
              âœ… Schema migrated successfully  
              âœ… Production registry updated
              âœ… All versions preserved
```

### **ğŸ”„ Schema Evolution for Growth**

```
Developer: "Our user profile schema needs to support international addresses. 
           Can you add country and postal_code fields that are backward compatible?"

AI Assistant: I'll add those fields as optional with defaults to maintain backward compatibility.
              [Registers new schema version]
              âœ… New version registered successfully
              âœ… Backward compatibility verified
              âœ… Ready for gradual rollout
```

### **ğŸ“Š Compliance and Documentation**

```
Data Governance: "Export all schemas from our fintech context for the audit."

AI Assistant: I'll export all fintech schemas with their documentation and evolution history.
              [Generates comprehensive export]
              âœ… 12 schemas exported in JSON format
              âœ… Evolution history included
              âœ… Compliance metadata attached
```

---

## ğŸš€ Complete Demo Ecosystem

We've built a comprehensive demonstration that showcases enterprise-grade schema management:

<table>
<tr>
<td width="25%" align="center">
<h3>ğŸ¤– <a href="https://github.com/aywengo/kafka-schema-reg-mcp">MCP Server</a></h3>
<p>The core AI integration that connects any MCP client to Kafka Schema Registry</p>
<ul>
<li>48 MCP tools for complete schema operations</li>
<li>Multi-registry support (dev/staging/prod)</li>
<li>Context-based organization</li>
<li>GitHub OAuth integration</li>
</ul>
</td>
<td width="25%" align="center">
<h3>ğŸ—ï¸ <a href="https://github.com/kafka-schema-reg-mcp-demos/demo-deployment">Demo Environment</a></h3>
<p>Production-ready deployment with realistic infrastructure</p>
<ul>
<li>3-tier registry setup</li>
<li>GitHub OAuth authentication</li>
<li>Monitoring & observability</li>
<li>Docker Compose deployment</li>
</ul>
</td>
<td width="25%" align="center">
<h3>ğŸ¨ <a href="https://github.com/kafka-schema-reg-mcp-demos/demo-schemas">Business Schemas</a></h3>
<p>Real-world schemas from multiple industries</p>
<ul>
<li>E-commerce platform</li>
<li>IoT sensor data</li>
<li>Financial services</li>
<li>SaaS multi-tenancy</li>
</ul>
</td>
<td width="25%" align="center">
<h3>ğŸ“š <a href="https://github.com/kafka-schema-reg-mcp-demos/demo-docs">Documentation</a></h3>
<p>Comprehensive guides and tutorials</p>
<ul>
<li>Getting started guides</li>
<li>Architecture deep-dives</li>
<li>Use case walkthroughs</li>
<li>Integration patterns</li>
</ul>
</td>
</tr>
</table>

---

## ğŸ”— Apache Kafka & Confluent Integration

Built for the **[Apache Kafka](https://kafka.apache.org/)** ecosystem with full **[Confluent Schema Registry](https://docs.confluent.io/platform/current/schema-registry/fundamentals/index.html)** compatibility:

### **ğŸ¯ Supported Platforms**
- **[Confluent Platform](https://www.confluent.io/product/confluent-platform/)** - Full enterprise distribution with advanced features
- **[Confluent Cloud](https://www.confluent.io/confluent-cloud/)** - Fully managed cloud service
- **[Apache Kafka](https://kafka.apache.org/)** - Open source distribution
- **[Amazon MSK](https://aws.amazon.com/msk/)** - AWS managed Kafka with Schema Registry
- **[Azure Event Hubs](https://docs.microsoft.com/en-us/azure/event-hubs/)** - Azure managed Kafka service

### **ğŸ“‹ Schema Format Support**
- **[Apache Avro](https://avro.apache.org/)** - Primary focus with full evolution support
- **[JSON Schema](https://json-schema.org/)** - Web-friendly schema definition
- **[Protocol Buffers](https://protobuf.dev/)** - Google's language-neutral serialization

### **ğŸ”§ Enterprise Features**
- **[Schema Evolution](https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility)** - Backward, forward, and full compatibility
- **[Schema Contexts](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#contexts)** - Logical grouping and multi-tenancy
- **[Compatibility Levels](https://docs.confluent.io/platform/current/schema-registry/avro.html#compatibility-types)** - Fine-grained evolution control
- **[Subject Naming](https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#subject-name-strategy)** - Flexible naming strategies

---

## ğŸŒŸ Real-World Schema Examples

Our demo includes production-ready schemas across multiple industries:

### **ğŸ›’ E-commerce Platform**
```json
{
  "type": "record",
  "name": "UserProfile", 
  "namespace": "com.ecommerce.user",
  "fields": [
    {"name": "user_id", "type": "string"},
    {"name": "email", "type": "string"},
    {"name": "preferences", "type": {
      "type": "record",
      "name": "UserPreferences",
      "fields": [
        {"name": "newsletter", "type": "boolean", "default": true},
        {"name": "notifications", "type": "boolean", "default": true}
      ]
    }}
  ]
}
```

### **ğŸ¦ Financial Services**
```json
{
  "type": "record",
  "name": "Transaction",
  "namespace": "com.fintech.payments", 
  "fields": [
    {"name": "transaction_id", "type": "string"},
    {"name": "amount", "type": {"type": "bytes", "logicalType": "decimal"}},
    {"name": "currency", "type": "string"},
    {"name": "compliance_data", "type": {
      "type": "record", 
      "name": "ComplianceInfo",
      "fields": [
        {"name": "kyc_verified", "type": "boolean"},
        {"name": "risk_score", "type": "int"}
      ]
    }}
  ]
}
```

### **ğŸŒ IoT Platform** 
```json
{
  "type": "record",
  "name": "SensorReading",
  "namespace": "com.iot.sensors",
  "fields": [
    {"name": "device_id", "type": "string"},
    {"name": "timestamp", "type": {"type": "long", "logicalType": "timestamp-millis"}},
    {"name": "temperature", "type": "float"},
    {"name": "humidity", "type": "float"},
    {"name": "location", "type": {
      "type": "record",
      "name": "GeoLocation", 
      "fields": [
        {"name": "latitude", "type": "double"},
        {"name": "longitude", "type": "double"}
      ]
    }}
  ]
}
```

**ğŸ¨ Explore All Schemas:** [Demo Schemas Repository â†’](https://github.com/kafka-schema-reg-mcp-demos/demo-schemas)

---

## ğŸ“ˆ Evolution Patterns Demonstrated

### **âœ… Backward Compatible Evolution**
```
// v1: Basic user profile
{"name": "user_id", "type": "string"}
{"name": "email", "type": "string"}

// v2: Add optional preferences (backward compatible)
{"name": "preferences", "type": ["null", "UserPreferences"], "default": null}
```

### **ğŸ”„ Schema Migration Across Environments**
```
Development â†’ Staging â†’ Production
     â†“            â†“           â†“
Context: dev   Context: staging   Context: prod
Access: Full   Access: Limited    Access: ReadOnly
```

### **ğŸ¢ Multi-Tenant Organization**
```
ecommerce/          fintech/           iot-platform/
â”œâ”€â”€ user-profile    â”œâ”€â”€ transactions   â”œâ”€â”€ sensor-readings
â”œâ”€â”€ order-events    â”œâ”€â”€ accounts       â”œâ”€â”€ device-status  
â””â”€â”€ products        â””â”€â”€ compliance     â””â”€â”€ alerts
```

---

## ğŸ¯ Perfect For Your Team

### **ğŸ‘¨â€ğŸ’» Developers**
> *"Finally, schema management that doesn't interrupt my flow"*

**What you get:**
- Natural language schema operations in your favorite IDE
- Instant compatibility checking before deployment
- AI-assisted schema design and evolution
- Context-aware environment management

**Compatible with:** Claude Desktop, VS Code Copilot, Cursor, JetBrains IDEs

### **ğŸ”§ DevOps Engineers**  
> *"Multi-environment schema governance that actually works"*

**What you get:**
- Automated schema promotion pipelines
- Cross-registry migration and synchronization
- Production-safe readonly modes
- Comprehensive monitoring and observability

### **ğŸ“Š Data Engineers**
> *"Schema documentation and governance on autopilot"*

**What you get:**
- Automatic schema documentation generation
- Evolution tracking and compatibility analysis
- Bulk export and backup capabilities
- Compliance-ready audit trails

### **ğŸ¢ Platform Teams**
> *"Enterprise schema management without the enterprise complexity"*

**What you get:**
- Multi-tenant context isolation
- Role-based access control via GitHub
- Centralized schema registry management
- Self-service developer experience

---

## ğŸ”— Complete Ecosystem Links

| Component | Purpose | Repository | Status |
|-----------|---------|------------|---------|
| **ğŸ¤– MCP Server** | Core AI integration | [kafka-schema-reg-mcp](https://github.com/aywengo/kafka-schema-reg-mcp) | âœ… Production Ready |
| **ğŸ—ï¸ Demo Deployment** | Infrastructure & OAuth | [demo-deployment](https://github.com/kafka-schema-reg-mcp-demos/demo-deployment) | âœ… Ready to Deploy |
| **ğŸ¨ Demo Schemas** | Business examples | [demo-schemas](https://github.com/kafka-schema-reg-mcp-demos/demo-schemas) | âœ… 14 schemas, 39 versions |
| **ğŸ“š Documentation** | Guides & tutorials | [demo-docs](https://github.com/kafka-schema-reg-mcp-demos/demo-docs) | âœ… Comprehensive guides |

---

## ğŸ‰ Join the Future of Schema Management

### **â­ Star the Project**
Help others discover AI-powered schema management:
- â­ [kafka-schema-reg-mcp](https://github.com/aywengo/kafka-schema-reg-mcp)
- â­ [demo-deployment](https://github.com/kafka-schema-reg-mcp-demos/demo-deployment)  
- â­ [demo-schemas](https://github.com/kafka-schema-reg-mcp-demos/demo-schemas)

### **ğŸš€ Get Started Today**
1. **[Try the Local Demo â†’](#-option-1-local-development-setup)** - Full environment in 5 minutes
2. **[Read the Setup Guide â†’](#-quick-setup-guide)** - Comprehensive deployment instructions
3. **[Configure Your IDE â†’](#-client-configuration-examples)** - Connect your favorite AI assistant
4. **[Explore Use Cases â†’](#-enterprise-use-cases)** - Real-world scenarios

### **ğŸ¤ Community & Support**
- **Issues**: [GitHub Issues](https://github.com/aywengo/kafka-schema-reg-mcp/issues)
- **Discussions**: [GitHub Discussions](https://github.com/aywengo/kafka-schema-reg-mcp/discussions)
- **Contributions**: See [Contributing Guide](https://github.com/aywengo/kafka-schema-reg-mcp/blob/main/CONTRIBUTING.md)

---

**ğŸ¤– Ready to transform your schema management with AI?** [Start with the local setup â†’](#-option-1-local-development-setup)

---

<div align="center">

**Built with â¤ï¸ for the [Apache Kafka](https://kafka.apache.org/) and AI community**

[Documentation](https://github.com/kafka-schema-reg-mcp-demos/demo-docs) â€¢ [Demo](https://github.com/kafka-schema-reg-mcp-demos/demo-deployment) â€¢ [Schemas](https://github.com/kafka-schema-reg-mcp-demos/demo-schemas) â€¢ [MCP Server](https://github.com/aywengo/kafka-schema-reg-mcp)

**Powered by:** [Apache Kafka](https://kafka.apache.org/) â€¢ [Confluent Schema Registry](https://docs.confluent.io/platform/current/schema-registry/) â€¢ [Apache Avro](https://avro.apache.org/) â€¢ [Model Context Protocol](https://modelcontextprotocol.io/)

</div>
